import vk_api
from vk_api.exceptions import VkApiError
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import json
import os
from dotenv import load_dotenv
from collections import defaultdict

load_dotenv()


class VKUniversityTracker:
    def __init__(self):
        self.vk_session = vk_api.VkApi(token=os.getenv("VK_ACCESS_TOKEN"))
        self.vk = self.vk_session.get_api()
        self.stats = {
            'total_posts': 0,
            'unique_users': set(),  # –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ
            'daily_stats': defaultdict(lambda: {
                'posts': 0,
                'likes': 0,
                'views': 0,
                'comments': 0,
                'reposts': 0
            }),
            'universities': {
                'spbu': {'count': 0, 'posts': []},
                'msu': {'count': 0, 'posts': []}
            }
        }

    def search_posts(self, university_keywords, days=30):
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        try:
            results = self.vk.newsfeed.search(
                q="|".join(university_keywords),
                start_time=int(start_date.timestamp()),
                end_time=int(end_date.timestamp()),
                count=200,
                extended=1
            )
            self._process_results(results)
        except VkApiError as e:
            print(f"–û—à–∏–±–∫–∞ VK API: {e}")

    def _process_results(self, results):
        for item in results['items']:
            post_date = datetime.fromtimestamp(item['date']).strftime('%Y-%m-%d')
            university = self._identify_university(item['text'])

            self.stats['total_posts'] += 1
            self.stats['unique_users'].add(item['from_id'])
            self.stats['daily_stats'][post_date]['posts'] += 1
            self.stats['daily_stats'][post_date]['likes'] += item.get('likes', {}).get('count', 0)
            self.stats['daily_stats'][post_date]['views'] += item.get('views', {}).get('count', 0)
            self.stats['daily_stats'][post_date]['comments'] += item.get('comments', {}).get('count', 0)
            self.stats['daily_stats'][post_date]['reposts'] += item.get('reposts', {}).get('count', 0)

            if university:
                self.stats['universities'][university]['count'] += 1
                self.stats['universities'][university]['posts'].append({
                    'id': item['id'],
                    'date': post_date,
                    'text': item['text'][:200] + '...' if len(item['text']) > 200 else item['text'],
                    'likes': item.get('likes', {}).get('count', 0),
                    'views': item.get('views', {}).get('count', 0),
                    'comments': item.get('comments', {}).get('count', 0),
                    'reposts': item.get('reposts', {}).get('count', 0)
                })

    def _identify_university(self, text):
        text = text.lower()
        if any(word in text for word in ['—Å–ø–±–≥—É', '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥—Å–∫–∏–π', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–ü–ú-–ü–£']):
            return 'spbu'
        elif any(word in text for word in ['–º–≥—É', '–º–æ—Å–∫–æ–≤—Å–∫–∏–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π']):
            return 'msu'
        return None

    def generate_reports(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        report_data = {
            'total_posts': self.stats['total_posts'],
            'unique_users_count': len(self.stats['unique_users']),
            'unique_users': list(self.stats['unique_users']),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º set –≤ list
            'daily_stats': dict(self.stats['daily_stats']),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º defaultdict –≤ dict
            'universities': self.stats['universities']
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON
        with open('vk_university_stats.json', 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        # –ì—Ä–∞—Ñ–∏–∫–∏
        self._create_plots()

        # Excel –æ—Ç—á–µ—Ç
        self._generate_excel_report()

    def _create_plots(self):
        dates = sorted(self.stats['daily_stats'].keys())
        posts = [self.stats['daily_stats'][d]['posts'] for d in dates]

        plt.figure(figsize=(12, 6))
        plt.plot(dates, posts, marker='o')
        plt.title('–î–∏–Ω–∞–º–∏–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –ø–æ –¥–Ω—è–º')
        plt.xlabel('–î–∞—Ç–∞')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('posts_dynamics.png')
        plt.close()

        uni_counts = [
            self.stats['universities']['spbu']['count'],
            self.stats['universities']['msu']['count']
        ]

        plt.figure(figsize=(8, 8))
        plt.pie(uni_counts, labels=['–°–ü–±–ì–£', '–ú–ì–£'], autopct='%1.1f%%')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤')
        plt.savefig('universities_distribution.png')
        plt.close()

    def _generate_excel_report(self):
        with pd.ExcelWriter('vk_university_report.xlsx') as writer:
            # –°–≤–æ–¥–∫–∞
            summary_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π', '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π',
                            '–£–ø–æ–º–∏–Ω–∞–Ω–∏–π –°–ü–±–ì–£', '–£–ø–æ–º–∏–Ω–∞–Ω–∏–π –ú–ì–£'],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    self.stats['total_posts'],
                    len(self.stats['unique_users']),
                    self.stats['universities']['spbu']['count'],
                    self.stats['universities']['msu']['count']
                ]
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='–°–≤–æ–¥–∫–∞', index=False)

            # –ü–æ –¥–Ω—è–º
            daily_data = []
            for date, stats in self.stats['daily_stats'].items():
                daily_data.append({
                    '–î–∞—Ç–∞': date,
                    '–ü—É–±–ª–∏–∫–∞—Ü–∏–∏': stats['posts'],
                    '–õ–∞–π–∫–∏': stats['likes'],
                    '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã': stats['views'],
                    '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': stats['comments'],
                    '–†–µ–ø–æ—Å—Ç—ã': stats['reposts']
                })
            pd.DataFrame(daily_data).to_excel(writer, sheet_name='–ü–æ –¥–Ω—è–º', index=False)

            # –ü—Ä–∏–º–µ—Ä—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π
            posts_data = []
            for uni in ['spbu', 'msu']:
                for post in self.stats['universities'][uni]['posts'][:10]:
                    posts_data.append({
                        '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç': '–°–ü–±–ì–£' if uni == 'spbu' else '–ú–ì–£',
                        '–î–∞—Ç–∞': post['date'],
                        '–¢–µ–∫—Å—Ç': post['text'],
                        '–õ–∞–π–∫–∏': post['likes'],
                        '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã': post['views'],
                        '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': post['comments'],
                        '–†–µ–ø–æ—Å—Ç—ã': post['reposts']
                    })
            pd.DataFrame(posts_data).to_excel(writer, sheet_name='–ü—Ä–∏–º–µ—Ä—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π', index=False)


if __name__ == "__main__":
    tracker = VKUniversityTracker()

    spbu_keywords = ["–°–ü–±–ì–£", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç","—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "–ü–ú-–ü–£"]
    msu_keywords = ["–ú–ì–£", "–ú–æ—Å–∫–æ–≤—Å–∫–∏–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç"]

    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ VK...")
    tracker.search_posts(spbu_keywords + msu_keywords, days=30)

    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤...")
    tracker.generate_reports()

    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –û—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª–∞—Ö:")
    print("- vk_university_stats.json")
    print("- vk_university_report.xlsx")
    print("- posts_dynamics.png")
    print("- universities_distribution.png")