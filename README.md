Task 2
# Web crawler

Python-скрипт для анализа структуры веб-сайтов, сбора статистики и обнаружения ресурсов.

## Возможности

- Рекурсивный обход сайтов до указанной глубины
- Классификация ссылок (внутренние/внешние)
- Обнаружение поддоменов
- Поиск документов (PDF, DOC, DOCX)
- Сбор детальной статистики о сайте
- Корректная обработка редиректов и битых ссылок

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/вашusername/web-crawler.git
cd web-crawler
```

2. Установка зависимостей

```bash
poetry install
```

## Запуск

python src/crawler.py [URL] [--deep ГЛУБИНА]
